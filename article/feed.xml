<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Articles on 0xab.de</title><link>/article/</link><description>Recent content in Articles on 0xab.de</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 24 Jan 2021 00:00:00 +0000</lastBuildDate><atom:link href="/article/feed.xml" rel="self" type="application/rss+xml"/><item><title>SQL 基础——数据模型</title><link>/article/2021/01/data-model/</link><pubDate>Sun, 24 Jan 2021 00:00:00 +0000</pubDate><guid>/article/2021/01/data-model/</guid><description>本文中以斜体表示的定义部分内容可能相对晦涩，可以参照后续解释进行理解。
数据库的作用是存储数据，而数据是来自于现实世界中的，所以数据库中描述的往往是对现实世界数据特征的抽象。这种抽象的方式被称为数据库的数据模型。关系模型即是其中一种抽象方式。
层次模型 一个数据模型首先要能够反映现实世界中的关联关系，这样才能够针对这种关系设计数据库结构。其次，当现实世界中的关系发生变化时，数据模型也要有随之改变的能力。在关系模型出现之前，存在层次模型（Hirearchical Model）和网状模型（Network Model）两个数据模型。层次模型是数据库中最早出现的数据模型，它定义了：只有一个根结点；根以外的结点有且只有一个双亲结点。 也就是说，层次模型是一棵树。
图1，层次模型
针对图1的层次模型来讲，它的最高的层次是 College，College 和 Department、Infrastructure 之间存在归属关系，在层次模型中将这种关系用线连起来。它们之间的联系是父子之间一对多的关系。也就是说，一个结点只能归属于另一个结点。所以在层次模型中，只能处理一对多的实体联系。
想象这样一种情况：学生张三修了双学位，而恰好这两个专业属于不同的两个学院，那么层次模型应该如何构造？也就是说，层次模型难以表达多对多的结构。
另外，在 Department 和 Students 之间加入 Class 结点，这显然是合理的。如果用户在设计数据库结构时没有考虑周到，导致后续对结构进行更改，这势必会对整体结构造成很大的影响。
网状模型 在层次模型中，线用来表示层级之间的归属关系。但是在现实世界中，许多事物之间的联系是不存在层次关系的。把这种层级关系转换成事物之间的关联关系，同样用线将它们连起来，这样就可以得到一个网式的结构，称为网状模型。
图2，网状模型
在网状模型中，一个实体可以与多个实体存在联系，这种联系可以是任何方式的，包括归属关系。假设图2描述的是一种组织架构上的关系，D1 在属于 C2 的同时，也可以属于 C3，这样就能够解决层级模型难以解决的问题：无法表达多对多的关系。网状模型能够表达现实世界中的复杂关系。但是随着网状模型的规模扩大，整个模型的结构越来越复杂，每次对一个数据的修改势必会影响许多相关数据。
关系模型 既然网状模型能够解决多对多的问题，只是结构较为复杂，如果将网状模型按照一个个实体拆分，并附加上它们之间的关联关系，是否能够在表达多对多关系的同时简化结构呢？
按照上述思路，每个实体单独拆分，同时实体间的关系也可以看作一个描述它们之间关系的实体。图3描述了一个从 Supplier 购买 Chemical 的关系。想象一次采购的过程：可以同时采购多种 Chemical，每种 Chemical 有各自的 Supplier；同时可能在一个 Supplier 采购了多种 Chemical；这次购买要记录购买的数量、总价和时间；每个 Chemical 和 Supplier 的详细信息当然也要记录下来。按照 Chemical, Supplier 这两个实体，以及它们之间的关系（Order）拆分，就可以得到图3的实体——关系模型。
图3，从 Supplier 采购 Chemicla 的 E-R 图
关系模型设计完成后，用户发现忘记记录采购者的信息，这该怎么办？在该模型中，只需要加入采购者实体，并将其与 Order 关联起来，不需要对其他实体进行修改。可以看出，关系模型降低了实体间的耦合度，使得结构的可维护性大大增强。
在 E-R 图 （Entity Relationship Diagram）中，方形框代表实体，椭圆形框代表实体或关系的属性，菱形框代表实体间的联系，实体、属性、联系之间用实线连接起来。</description></item><item><title>SQL 基础——历史和关系模型</title><link>/article/2021/01/sql-introduction/</link><pubDate>Sat, 23 Jan 2021 00:00:00 +0000</pubDate><guid>/article/2021/01/sql-introduction/</guid><description>学习新概念经常陷入的误区之一是：先生硬地记下，而不是尝试理解其含义。读书时老师经常讲“要理解着记忆”，这个思想在此处也同理。一个新概念必然是为了解决一个问题而出现的，所以在介绍新概念之前，要首先了解其诞生的历史背景。
1970年代，IBM 的工程师从 Edgar F. Codd 的关系模型[1]中得到灵感，设计了一个用于操作他们的半结构化数据库 System R[2]的语言：SEQUEL (Structured English Query Language)，由于商标原因后改称为 SQL。这也是经常有人将 SQL 读作 [siːkwəl] 的原因。SQL 先后在 System/38, SQL/DS, DB2 等基于 System R 的数据库上大放异彩，这让Oracle (Relational Software, Inc.) 从中得到了灵感。1979年，Oracle 发布了他们的第一个基于 SQL 的商用数据库：Oracle V2。SQL 在商用关系型数据库上的成功使得其成为了事实标准，ANSI 和 ISO 也随后相继采用 SQL 作为标准。
SQL 是 Structured Query Language 的缩写，从字面上翻译过来是“结构化查询语言”。“查询”和“语言”两词容易理解，那么何为“结构化”？既然 SQL 为操作关系模型而设计的，那么要解释“结构化”就首先要解释什么是“关系模型”。
关系模型认为数据都是以关系的形式存在的。想象一张标准的 Excel 表，每一行代表着一条记录（元组），每一列代表着这条记录中的一个属性（字段）。在关系模型中，将这张表的结构称为关系模式 (relation schema), 表的值被称为关系。关系模式是对关系的描述。想象一张学生信息的表格，每个学生都要填写其姓名、学号、专业班级等信息，这些信息就是这个关系的属性；每个学生信息都是表格中的一行记录/元组。在学生填写表格之前。需要在表头给出每一列所需要填写的信息，表头中对每一列给出的约束就是关系模式。学生填写的一行行数据的集合就是关系，关系是关系模式在某一时刻的内容。关系模式规定了关系的结构，SQL 即是被设计用来对这种结构进行查询的语言。
表1，学生表格的一种结构
姓名 学号 专业 张三 222016XXXX 软件工程 SQL 在成为结构化查询的事实标准后，其使用的范围已经不局限于 RDBMS 领域。比如在大数据领域中，几乎所有组件都离不开 Google 提出的“三驾马车”。在开源实现中，HDFS 和 MapReduce 这两驾马车组成了 Hadoop 的核心。但是 Hadoop 有非常陡峭的学习曲线，颇有“不食人间烟火”的高冷意味。既然 SQL 的通用性这么强，能否通过 SQL 来实现 Hadoop 的使用？于是 Hive 应运而生了。Hive 是一个数据仓库，它能够将 Hive SQL (一种类似 SQL 的语言[4])转换成 MapReduce 任务，从而提交到 Hadoop 集群上。</description></item><item><title>Spark Papers</title><link>/article/2020/11/spark-papers/</link><pubDate>Fri, 13 Nov 2020 00:00:00 +0000</pubDate><guid>/article/2020/11/spark-papers/</guid><description>Spark: Cluster Computing with Working Sets MapReduce （下称 MR）任务包含主要五两个步骤：Map、Sort、Combine、Shuffle、 Reduce，每个 MR 任务在 Map 将数据阶段将数据转换成 K-V 的形式；Reduce 在不同的机器上作聚合运算。Shuffle 更是涉及到巨大的 I/O 操作（主要是网络 I/O）。每个 MR 任务最终会将计算结果写回存储系统。
由于 MR 任务的最终结果会写回存储，那么有两种经典场景对于它来说是低效的：
迭代任务（迭代机器学习算法） 交互式数据分析工具 Spark 提出了 RDD (Resilient Distributed Dataset) 模型来处理此类问题。RDD 是一个被分布在一组机器上的只读的对象集，当一个分区丢失时 RDD 能够很快通过重新计算的方式来重建。RDD 能够被保存在内存中，并以类似 MR 的 并行操作方式 得到重用。RDD 通过一种叫做 血统（lineage） 的概念实现容错：如果 RDD 的一部分丢失了，那么 RDD 有足够的信息（该 RDD 是怎么从其他 RDD 计算出来的）来重建该部分。
在 Spark 中，RDD 以 Scala 对象的形式存在。并且 RDD 能够通过以下几种形式构造出来：
来自共享文件系统（如 HDFS）中的一个文件 并行化（parallelizing） 一个 Scala 集合 转化（transforming）于一个已经存在的 RDD 改变一个已存在 RDD 的持久性（persistence） cache：将 RDD 暂存于内存以便稍后重用 save：将 RDD 存于类似 HDFS 的分布式文件系统 对于 cache 这种情况来说，如果集群中没有足够的内存来缓存一个数据集（dataset）的所有部分，那么 Spark 会在使用它们时重新计算。</description></item><item><title>Google File System</title><link>/article/2020/03/google-file-system/</link><pubDate>Sun, 29 Mar 2020 00:00:00 +0000</pubDate><guid>/article/2020/03/google-file-system/</guid><description>GFS 是谷歌开发的分布式文件系统，也是上一篇 MapReduce 最终输出文件的存放位置。
设计概述 以下内容简述了 GFS 的设计架构。包括系统的的细节，以及如此设计的原因。
假设 该系统在以下前提设计实现：
该系统由许多机器组成，这些机器经常会出错。所以系统必须持续检测以便能够检查、容忍错误，并且能够恢复回来。 该系统支持小型文件，但是不会对其作出优化。 关注性能的应用经常对一批读操作进行排序，以便提高性能。 在文件写入之后，很少会再次修改。 系统必须高效地处理好并发问题。 高且平稳的带宽比低延迟重要。 接口 GFS 提供了和文件系统类似的接口。文件以文件路径名严格组织。除了传统的 CRUD 之外，GFS 还提供了快照和 record append。快照能高效地复制一个文件或目录，record append 用来解决多个客户端的并发问题。
架构 一个 GFS 集群包括一个 master 和多个 chunkserver，同时 master 可以被多个 client 访问到。如图一。 文件通常被分为固定大小的 chunk 。在 chunk 被创建时，master 分配给它一个64位全局常量 chunk handle 。 chunkserver 将 chunk 作为 linux 文件存储在本地磁盘，并且根据 chunk handle 和字节区间进行读写。每个 chunk 在多个 chunkserver 上都有冗余。
master 上保存了所有文件系统的元数据。包括命名空间，访问控制信息，文件到 chunk 的映射和 chunk 的位置。也控制像 chunk 租约，孤儿 chunk 的 GC，chunkserver 之间的 chunk 迁移等系统活动。master 还定期向 chunkserver 发送心跳包收集其状态。 client 与 master 交互来操作元数据，而对数据的操作直接与 chunkserver 通信。 client 和 chunkserver 都不缓存文件数据。一般对客户端来说，文件都太大了。而得益于 linux buffer cache，chunkserver 也不用再做缓存了（linux 会将访问的磁盘文件缓存在内存里）。</description></item><item><title>Google MapReduce</title><link>/article/2020/03/google-map-reduce/</link><pubDate>Fri, 20 Mar 2020 00:00:00 +0000</pubDate><guid>/article/2020/03/google-map-reduce/</guid><description>无论是出于对分布式系统的兴趣，还是对一个未来的 Hadooper 来说，这篇论文都值得一读。号称为 Google “三驾马车”之一，同时也作为6.824 LEC 1的 preparation, 其重要性也随之体现。趁着时间充裕，抓紧读了读并尝试着手进行后面的 lab。
概念 Google 提出了一种 Map-Reduce 的模型。map 将一对键值对处理成另外一组中间键值对， reduce 将这些中间键值对中 key 相同的合并起来。 系统关注的除了处理数据本身之外，还有调度机器之间程序的运行、处理机器故障以及管理机器之间的通信。
编程模型 就如前面提到的，用户编写的 Map 将所有的输入处理成中间状态的键值对，MapReduce 根据中间状态的 Key 将其整理到一起（因为数据在不同的机器上），并将其交给 Reduce。
之后，同样是用户编写的 Reduce 将 Key 相同的中间键值对合并到一起。合并的数据集可能只是一小部分。
下面是一个单词计数的例子：
map (String key, String value) // key document name // value document content for each word w int value: EmitIntermediate (w, &amp;quot;1&amp;quot;); reduce (String key, Iterator value) // key a word // values a list of counts int result = 0; for each v in values: result += ParseInt (v); Emit(AsString (result)); map 函数将出现过的单词与其出现过的次数相关联，这里是1。 reduce 函数将相同单词出现的次数求和。</description></item><item><title>Solution for switching between lowercase and Chinese pinyin with Caps Lock in Jetbrains IDEs</title><link>/article/2020/02/solution-for-switching-pinyin-ime-state-in-jbs/</link><pubDate>Wed, 12 Feb 2020 00:00:00 +0000</pubDate><guid>/article/2020/02/solution-for-switching-pinyin-ime-state-in-jbs/</guid><description>TL;DR:
Add TICapsLockLanguageSwitchCapable - true to your input method&amp;rsquo;s Info.plist[1]
Background Last month I encountered a problem with Chinese input method (Rime, Baidu, Sogou, etc), the symptoms is that I couldn&amp;rsquo;t switch between pinyin and lowercase letters with the Caps Lock which can pressed by my little finger in Jetbrains IDEs, which has been my habit since I used macOS.
Before using third-party input methods, it works well with apple pinyin method.</description></item><item><title>A note of android reverse engineering</title><link>/article/2020/02/reverse-engineering/</link><pubDate>Sat, 01 Feb 2020 00:00:00 +0000</pubDate><guid>/article/2020/02/reverse-engineering/</guid><description>起因 凌晨在 QQ 空间看到一个同校同学发布了一款 App，正在邀请别人参加内测。正巧最近我也在帮朋友写一个小应用，便下载来研究一下。应用的主题很常见，主打校内论坛、交友功能，大概猜到是怎么回事，还是先抓包看看吧。
抓包 Charles 这个工具就不用说了，基本抓过包的朋友都用过。不过想要抓手机应用，前提要求手机和电脑在一个局域网络中。设置代理和安装证书这两个步骤很容易找到教程，这里不再赘述。需要注意的是 Android 7 以后按谷歌要求需要额外修改 APP 的网络安全性配置，我这里参考这篇文章 [1] 得以解决。
抓到包之后看了一眼 Request 和 Response 格式，看上去不太规范。而且虽然加入了 token，但是很多接口没有鉴权，拿到接口直接请求就能修改所有用户的资料。由于是内测，我将开发者的昵称修改以提示其漏洞，同时也在内测群里反馈了，截止目前接口还没有修改。除此之外，修改密码等接口中的密码竟然是明文传输的，这让我不能不担心是否在数据库中也是明文存储密码？于是诞生了 hack 进数据库的想法。
调研 在处理数据库相关问题之前，先判断出其应用的技术栈。后端是拿 php 写的，而据我所知 php 框架经常爆出漏洞，在此基础之上发现是 thinkphp v5.0.24，而此版本已将漏洞修复了。此外又发现服务器上安装了宝塔面板，开发者开启了安全登录入口，默认的后台地址被修改了，这条路径也只能放弃了。
撞库 我之前没有接触过安全方面的技术，但是最简单的撞库的思想还是有的。在网上找了一些密码字典，一共包括5000多个常用的密码，用 hydra[2] 暴力撞库，但是失败了。
SQL 注入 撞库失败后联想到 SQL 注入的方式，找到了 sqlmap[3] 这个工具。拿几个接口都测了一下，没有发现注入点这条路也只能放弃。
逆向工程 既然服务端没有收获，那么就尝试从客户端入手。拿来 apk 解压得到 dex 文件，果然没有加壳。用 dex2jar[4]将其转成 jar。这里遇到一个问题[5]，在 GitHub 上最新的 release(2.1 or later) 已经解决。之后用 Java Decompiler[6] 打开 jar 查看源码。仔细查找后，奇怪地发现所有包都是导入的依赖，没有域名对应的包，也没有开发者编写的代码。这明显不合理。后来想到用 adb 来找当前栈顶 Activity 的方法。
adb shell dumpsys activity activities | sed -En -e &amp;#39;/Running activities/,/Run #0/p&amp;#39; 结果竟然是 uni.</description></item><item><title>Summary of the year of 2019</title><link>/article/2019/12/summary-of-the-year/</link><pubDate>Tue, 31 Dec 2019 00:00:00 +0000</pubDate><guid>/article/2019/12/summary-of-the-year/</guid><description>今年各 App 年度报告发布地格外早，但这一年我也没有专注地使用哪一家的产品，也就只有 GitHub 三方报告里的那8万多行代码算得上是准确。2019年是求职的一年，但是亲人的离去给了我无穷的痛苦。这篇文章将以时间为线索总结我这一年以来的经历，以作纪念。
1月，也就是大三上学期期末正在和操作系统浴血奋战的时候。刚经历过第一次找实习碰壁，深知自己不足故对读研第一次有了想法，花了大概两个月的时间搞了比赛的项目[1]，同时晚上也随机地找两道算法题做一下，虽然最后比赛结果难以令人满意，此次项目经验在春招也派上了用场。
3月，入职 SAP。这段经历只能算得上是一个插曲，在这我没有任何归属感，也丝毫没有感受到公司的技术氛围，这坚定了我离职的想法，最终在6月离开了。
当我以为春招是4、5月时，它已经在3月悄然地拉开了帷幕。当时我自负地认为在同专业、乃至同校同届人的代码水平以及计算机基础都算得上拔尖，但是春招是与全国同届的本科生和研究生同台竞争。如井底娃的我自然受挫。自负的人往往在此情况更能激发出斗志，在被阿里、腾讯等大厂拒绝过之后潜心面向面试学习了三个月左右，在就要去中小厂实习的时候终于拿到了百度的 offer。当天直接把美团的面试拒绝了，这是我后悔的一点。
在同一个时间段，准备了半年的 GSoC(Jenkins) 也因为日后工作方向的原因放弃掉了。跟在蚂蚁的学长聊了聊并确定了学习路线，同时了解到了 ASoC(Dubbo) 并申请通过了。
6月19日，入职百度 EE。我不太喜欢这里的技术方向，但是导师关心，经理没有架子，同事关系融洽，我找不到更好的词语来形容这个氛围。但是工作了两个月我还是离职了，这完全出自我个人的原因，我不后悔拥有这段经历。
8月末，杭州，ASoC 的毕业典礼。很意外，除我之外18人中有一个是学长，还有一人是 Jenkins 社区中的朋友。遇到的人和他们的故事让我坚定了修炼技术的决心。
翌日，网易 HR 面。通过之后告知有加面（总监面），顺利通过。
9月，在学校投递了少数的大厂。无一例外全部 fail。做百度笔试（上海-基础架构研发）时收到了网易的正式 Offer，看到薪资之后下定决心考研。之后缺忘记了百度的测评。
10月9日，爷爷去世。放弃考研，安心补招。
直到12月，这期间笔试、面试过多家大厂，均失败（腾讯一面挂、阿里一面挂、头条一面挂、美团一面口头通过、挂，滴滴三面挂、快手一面挂、京东二面挂、拼多多笔试挂、AWS 笔试挂）。将近一年的战线让我疲惫不堪，想要放弃的心态让我不想准备面试。半年来读了许多书和文章，谁能想到最大的坎是在算法和一些可以被称为背诵的题目上。
直到今天，2019年的最后一天，我接到了百度 HR 的电话，老东家再次向我敞开了怀抱。这里面有多少是实习经历给我的加分？我不知道。 学海无涯，坚持读书、坚持代码、坚持刷题。让自己每天都有收获，这是我现在能够做的事。
明年我会在哪家公司？明年我会在哪个城市？谁知道呢，就让明天的我做决定吧。
[1] https://github.com/arjenzhou/flashjob-server</description></item><item><title>Open Source and I - After Alibaba Summer of Code</title><link>/article/2019/08/29/summer-of-code/</link><pubDate>Thu, 29 Aug 2019 00:00:00 +0000</pubDate><guid>/article/2019/08/29/summer-of-code/</guid><description>关于阿里巴巴编程之夏的介绍可以参考 AliOS-things 同学的文章 https://zhuanlan.zhihu.com/p/79863308
借秋招的一个间歇期，记录一下我的开源历程。算是对自己的人生阶段的一个记录。
从小学时使用开源软件成为受益者，到第一次到开源社区中成为贡献者，我用了十年。不求回报地默默贡献，得到他人的肯定便觉得欢欣雀跃，也许这就是开源的魅力所在。
图1，赵老师在 Jenkins 中文社区的发言
我第一次正式参与到开源项目中，是在去年的九月。
去年四月的时候，在上海有幸认识了家辉，我们当时便成为了朋友。也是通过他，我了解到了 GSoC。半年之后，觉得是开始套瓷的时间了，便想挑选几个社区来有针对性的交流。第一个关注的是 Apache 的 Kylin 社区，虽然主要开发者是中国人，但是方向和我期望的不太一样，所以后来没有选择它。后来在 GSoC-CN 中根据往年的申请情况，选择了 Jenkins 社区，巧合的是 Jenkins 中文社区刚刚成立，而 Jenkins 社区中活跃的参与者赵老师 @Rick 又是中国人，所以从九月到第二年的三月我便一直在 Jenkins 社区中做贡献，期间成为了 Jenkins-infra member。
图2，赵老师由 KK 宣布为最有价值参与者
转折发生在二月和三月。在年前我和赵老师提到过想申请他的 multibranch plugin，他也提醒过我多次要提早准备。但是我期间一直没有在其 gitter channel 中发言，二月的时候有一个印度的同学也参与到其中。同时在三月时春招受挫，和在蚂蚁的家纯学长聊了聊，决定放弃 GSoC，参与到 Kafka 中去。
图3，和学长的交流
四月的一个偶然机会，了解到 ASoC 的举办，而其中恰好有我想要深入学习的 Dubbo 社区，于是便在 issue 中留言。我没有马上得到回复，而我又不想错过这次机会，于是在 Jira 中留言、给社区发邮件、给导师发邮件、给 aliopensource 发邮件。久久没有得到回复的我有点绝望，当时又去接触了 Spring Cloud Alibaba 社区。后来乎兴老师在 Jira 中回复了我，@cvictory 也在 issue 中回复了我，aliopensource 和社区也都回复了我邮件，让我先写 proposal。有 GSoC 的经历，其实我的提案早就写完了，但是 ASoC 的提案描述相对来说不够具体，很难有针对性的给出解决方案，就这样踏上了漫长的交流之路&amp;hellip;</description></item><item><title>The analysis and modification of rules of ESLint</title><link>/article/2019/07/the-analysis-and-modification-of-eslint-rules/</link><pubDate>Wed, 03 Jul 2019 00:00:00 +0000</pubDate><guid>/article/2019/07/the-analysis-and-modification-of-eslint-rules/</guid><description>每个互联网大厂都有自己的编码规范，而对规范审查需要有代码扫描平台来对工程师的能力进行评估。在实习的两个月中，我负责的工作的一部分包括代码规范扫描方向，其中对 ESLint 以及 fecs 规则的修改及调整也包括在内。ESLint 在内部保留了一个仓库用于 JS 的规范检查，由于内部代码规范的问题，不可能直接将外部的拿来直接使用。对很少接触 JS 的我来说，npm 的包管理方式冗杂而烦乱，同时该模块是被集成在整个扫描平台中的，所以很少有有效的文档用来参考，通过不断地测试最后终于解决了该部分问题。
规则 no-new 要求 使用 new 关键字必须将其赋值给一个变量，如:
var Vue = new Vue({}) 而内部规范在 Vue 中可以不赋值
new Vue({}) 所以考虑对 ESLint 进行一些定制化配置。
查看官方文档无果之后，考虑找到开发人员，以下为交流过程：
arjenzhou: Hi, because I customized the rules, so I want to build and run eslint locally, what should I do?
platinumazure: @arjenzhou You should be able to install ESLint locally with npm install &amp;ndash;save-dev eslint, and then run with .</description></item></channel></rss>