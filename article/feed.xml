<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Articles on arjenzhou</title><link>/article/</link><description>Recent content in Articles on arjenzhou</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 16 Feb 2022 00:00:00 +0000</lastBuildDate><atom:link href="/article/feed.xml" rel="self" type="application/rss+xml"/><item><title>ZeroTier 实现内网穿透——入门篇</title><link>/article/2022/02/zerotier/</link><pubDate>Wed, 16 Feb 2022 00:00:00 +0000</pubDate><guid>/article/2022/02/zerotier/</guid><description>上周末逛 v2 看到评论区提到了 ZeroTier, 想起来家里路由器上 Openwrt 带了这个插件，虽然目前没有内网穿透的需求，但是趁着周末还是稍微研究了下。
应用场景 从标题中可以看出，ZeroTier 是实现内网穿透的一个手段。简单来说就是能够通过它来实现不同局域网之间的互相访问：在公司局域网能连到家里的网络（不要这么做）
原理 大致简单了解了一下，局域网中各设备通过互联网与 Zeroier 的“行星服务器”建立 P2P VPN 连接，如果两个设备能够通过 VPN 直连那么就直连，否则通过 ZeroTier 中继。
简单使用 登录并创建一个 Network 之后，使用 ZeroTier 客户端依据 Network ID 连接到该 Network 并认证后。为该网络分配一个网段，给设备分配 IP 并设置路由规则后就可以使用分配的 IP 互相访问了，是不是很简单？
注意，将路由器加入 ZeroTier 需要配置防火墙。
截图举个例子：
在 IPv4 Auto-Assign 部分，为网络设置 IP 段。 这里我将这个网络设置了 10.242.100.0/24 IP 段。
设置路由规则 分配 IP 段后要为局域网设置路由规则。
图中 192.168.6.0/24 是我家里的局域网 IP 段，10.242.100.0/24 是上面 ZeroTier 分配的 IP 段。</description></item><item><title>键盘对比：NIZ Plum, FILCO 圣手2代, HHKB Professional Hybrid</title><link>/article/2022/02/keyboard-review/</link><pubDate>Thu, 10 Feb 2022 00:00:00 +0000</pubDate><guid>/article/2022/02/keyboard-review/</guid><description>之前用的一直是大一刚入学200块买的达尔优的机械键盘，作为刚入学的经常在宿舍打游戏的大学生，这是一款很常见的键盘：RGB，茶轴，104键，要素齐全。
NIZ Plum mini 84 Pro (35g) 2019年2月，我入手了一副 NIZ Plum mini 84 Pro 35g。
这款键盘当初是打算在 Mac 上用的，经网友推荐我仔细挑选后选中了这款。上手的第一感受就是软，打字手感特别黏稠、松垮的感觉。“也许这就是静电容”，我心想。用过一段时间发现尤其在789附近的数字区，由于35g实在是太轻了，经常出现误触的情况，一按下去一片数字上屏。后来用附送的增重弹簧给核心区域的键增到45g，这时才刚刚好。让人不得不吐槽的是竟然没有送84个弹簧，而且大键装起来很麻烦。这款键盘的布局还是很合理的，有F区，方向键很紧凑，只是右面一列有点多余，导致经常不好定位回车键。
用了两年多，这款键盘的缺点逐渐暴露出来了：按键经常失灵且打字卡顿，只不过不是必现。考虑到这款键盘当时是发烧友制作，并不是成熟的产品，质量问题还勉强说的过去。只是现在摸起来还是比较粗糙的，不过最近的产品看评价不错，多半是从手感上来打的分。
FILCO Majestouch Convertible 2 Tenkeyless (Cherry MX Red) 这款键盘是我在工作之后买的，对它的第一印象就是：好看。奶绿色给人一种草原、牧场、奶牛的感觉。
这款键盘本不是为 Mac 设计的，这一点从其自带的 Windows 键就能看得出来。不过得益于 Karabiner-Elements, 我们能很方便的在将 Command 和 Option 对掉 (图中 Alt 键和 Windows 键盘对换了)
我手中的这把是红轴的，理论上是樱桃轴体中比较轻的一款。但是在尝试过静电容之后，红轴对我来说在长时间的编码之后还是相对重了一些。F区以及方向键的隔离能够避免误触的情况，也让它显得大了一些。但是随着我入了一个 trackpad 之后，我变得越来越懒了。我在工作时两只手腕完全不想动，写代码时能用 Vim 的地方用 Vim，不行就各种快捷键，最坏的情况才把手向下移去用 trackpad。而且用 Vim 时左小指频繁地去按 Control 键，时间久了越来越累。这让我转向它处另寻键盘。
HHKB Professional Hybrid (PD-KB800BN) 22年春节后，趁着一大批年会奖品流出，我赶紧入了一款双模 HHKB. 说实话，还是白色有刻的比较经典。相比 NIZ，HHKB 的键相对较硬，段落感比较明显，但是要比红轴大F舒服。
HHKB 的键位不必多说，Control 的位置堪称完美，只是我一直是用 Capslock 来切换输入法，现在被迫回到了 &amp;lt;C - Space&amp;gt; 的组合键。令人诟病的地方在于这个 Fn 和方向键，虽然相对来说我方向键用的比较少，工作时基本被 hjkl 替代了。但是在摸鱼的时候切换微信朋友聊天方向键还是必要的，在 Fn 的组合中虽然是可以通过右手一只手间接按出来方向键的，但是 Fn 这个位置真的是太太太远了。虽然 SW4 设置可以将左 Command 替换成 Fn，但是右 Command 的组合键非常令人绝望，让我不得不放弃。</description></item><item><title>谈谈我理解的 Raft</title><link>/article/2021/11/raft-talk/</link><pubDate>Mon, 08 Nov 2021 00:00:00 +0000</pubDate><guid>/article/2021/11/raft-talk/</guid><description>自几年前偶然得知 Raft 之后，便粗略了解了 Raft, Paxos, 共识（一致性）这些概念。当时的想法是：这些算法听起来就挺装逼的，赶紧去看看咋回事。等到认真一看 Raft 论文，20页，太多了还是算了吧。 等到过了几天，又发现了 Raft 官网有个动画，还挺易懂的，又简单看了看，明白了，可以出去装逼了。 再过几天一回忆，好像啥也没记住呢？虽然张无忌学太极拳也啥也没记住，但至少人家打出来了，咱也得找机会练练。这会儿又找到了 MIT 6.824, 正好赶上新学期开课了，跟着学吧。 没等学两天，一到 lab 就懒得做，Go 看不懂啊，又学了几天 Go。学完了感觉啥都会了，但是又啥也不会。还是先去找实习吧。
前年快写毕业论文的时候，附带个翻译英文文献的任务，又到了装逼的时候了，我就直接在 arXiv 上找了篇 Raft 和 Paxos 对比 的论文翻译了下，由于当时懒得排版，等到去年年底才扔到博客上。
论文翻译完，又感觉啥也没记住。但是快要去上班了，又没时间研究了，上了一年班之后又找来了 Martin Kleppmann 的公开课来看，没几天就看完了，当时看完觉得啥都懂了，现在回忆起来只记住了拜占庭那些东西，又联想到凯撒、庞贝&amp;hellip;又联想远了&amp;hellip;
从去年7月入职以来，搞了本影印的 DDIA 来看。看书么，必须得英文原文，不然咋装逼啊是不。按照每天一页的进度终于把这书看完了（其实一周200页，然后歇半年）。看到后面又提到共识机制，觉得有必要再重新捡起来 Raft 论文再读一下了。
手中的 Raft 这篇论文实际上时几个月之前在公司的打印机上打印的，并且当时详细地做了注解，但随后没有好好整理。这次又根据上次遗留的问题来作笔记，最后写下了这篇文章表达一下自己的见解。
前提 Raft 据说是性能相当于 Paxos, 效果相当于 Multi-Paxos 的一个一致性算法，但它更容易理解。
一致性算法（共识算法）的作用是什么呢？是为了维护一个集群中的节点的数据一致性，但这个数据一致性不要求每个时刻所有节点上的数据都是一样的，而是整个集群对外看起来像是一样的。这就又让人迷惑了，既然你每个节点的数据都有可能不一样，那怎么能看起来是一样的呢？Raft 就采用了一个特别民主的方式，让大家去投票，只要超过半数的节点的数据/状态是一样的，那么这个集群的状态就是这样的。这种 Majority 的思想在很多算法/系统中都被采用。
既然要超过半数的节点达成一致，那么也就是说至少它们之间要互相交流，不然怎么能达成一致呢？设计过稍微复杂点的系统的人都知道，这个命题一听就很难，n 个节点每两个交流就得 n 的阶乘次了，这题还是让别人做吧。开玩笑，咱是那怂人吗？说上咱就上 (指 Raft)。Raft 简化了达成共识的条件，它描述了一个单 leader 的集群，leader 来决定是否更新到某个状态。这可比多 leader 或者无 leader 的容易理解多了，谁是领导听谁的呗，Majority + leader，在我们这叫民主集中制。
在 Raft 论文中描述，它将问题简化成了 leader election 和 log replication.</description></item><item><title>Spark Papers</title><link>/article/2020/11/spark-papers/</link><pubDate>Fri, 13 Nov 2020 00:00:00 +0000</pubDate><guid>/article/2020/11/spark-papers/</guid><description>Spark: Cluster Computing with Working Sets MapReduce （下称 MR）任务包含主要五两个步骤：Map、Sort、Combine、Shuffle、 Reduce，每个 MR 任务在 Map 将数据阶段将数据转换成 K-V 的形式；Reduce 在不同的机器上作聚合运算。Shuffle 更是涉及到巨大的 I/O 操作（主要是网络 I/O）。每个 MR 任务最终会将计算结果写回存储系统。
由于 MR 任务的最终结果会写回存储，那么有两种经典场景对于它来说是低效的：
迭代任务（迭代机器学习算法） 交互式数据分析工具 Spark 提出了 RDD (Resilient Distributed Dataset) 模型来处理此类问题。RDD 是一个被分布在一组机器上的只读的对象集，当一个分区丢失时 RDD 能够很快通过重新计算的方式来重建。RDD 能够被保存在内存中，并以类似 MR 的 并行操作方式 得到重用。RDD 通过一种叫做 血统（lineage） 的概念实现容错：如果 RDD 的一部分丢失了，那么 RDD 有足够的信息（该 RDD 是怎么从其他 RDD 计算出来的）来重建该部分。
在 Spark 中，RDD 以 Scala 对象的形式存在。并且 RDD 能够通过以下几种形式构造出来：
来自共享文件系统（如 HDFS）中的一个文件 并行化（parallelizing） 一个 Scala 集合 转化（transforming）于一个已经存在的 RDD 改变一个已存在 RDD 的持久性（persistence） cache：将 RDD 暂存于内存以便稍后重用 save：将 RDD 存于类似 HDFS 的分布式文件系统 对于 cache 这种情况来说，如果集群中没有足够的内存来缓存一个数据集（dataset）的所有部分，那么 Spark 会在使用它们时重新计算。</description></item><item><title>Google File System</title><link>/article/2020/03/google-file-system/</link><pubDate>Sun, 29 Mar 2020 00:00:00 +0000</pubDate><guid>/article/2020/03/google-file-system/</guid><description>GFS 是谷歌开发的分布式文件系统，也是上一篇 MapReduce 最终输出文件的存放位置。
设计概述 以下内容简述了 GFS 的设计架构。包括系统的的细节，以及如此设计的原因。
假设 该系统在以下前提设计实现：
该系统由许多机器组成，这些机器经常会出错。所以系统必须持续检测以便能够检查、容忍错误，并且能够恢复回来。 该系统支持小型文件，但是不会对其作出优化。 关注性能的应用经常对一批读操作进行排序，以便提高性能。 在文件写入之后，很少会再次修改。 系统必须高效地处理好并发问题。 高且平稳的带宽比低延迟重要。 接口 GFS 提供了和文件系统类似的接口。文件以文件路径名严格组织。除了传统的 CRUD 之外，GFS 还提供了快照和 record append。快照能高效地复制一个文件或目录，record append 用来解决多个客户端的并发问题。
架构 一个 GFS 集群包括一个 master 和多个 chunkserver，同时 master 可以被多个 client 访问到。如图一。 文件通常被分为固定大小的 chunk 。在 chunk 被创建时，master 分配给它一个64位全局常量 chunk handle 。 chunkserver 将 chunk 作为 linux 文件存储在本地磁盘，并且根据 chunk handle 和字节区间进行读写。每个 chunk 在多个 chunkserver 上都有冗余。
master 上保存了所有文件系统的元数据。包括命名空间，访问控制信息，文件到 chunk 的映射和 chunk 的位置。也控制像 chunk 租约，孤儿 chunk 的 GC，chunkserver 之间的 chunk 迁移等系统活动。master 还定期向 chunkserver 发送心跳包收集其状态。 client 与 master 交互来操作元数据，而对数据的操作直接与 chunkserver 通信。 client 和 chunkserver 都不缓存文件数据。一般对客户端来说，文件都太大了。而得益于 linux buffer cache，chunkserver 也不用再做缓存了（linux 会将访问的磁盘文件缓存在内存里）。</description></item><item><title>Google MapReduce</title><link>/article/2020/03/google-map-reduce/</link><pubDate>Fri, 20 Mar 2020 00:00:00 +0000</pubDate><guid>/article/2020/03/google-map-reduce/</guid><description>无论是出于对分布式系统的兴趣，还是对一个未来的 Hadooper 来说，这篇论文都值得一读。号称为 Google “三驾马车”之一，同时也作为6.824 LEC 1的 preparation, 其重要性也随之体现。趁着时间充裕，抓紧读了读并尝试着手进行后面的 lab。
概念 Google 提出了一种 Map-Reduce 的模型。map 将一对键值对处理成另外一组中间键值对， reduce 将这些中间键值对中 key 相同的合并起来。 系统关注的除了处理数据本身之外，还有调度机器之间程序的运行、处理机器故障以及管理机器之间的通信。
编程模型 就如前面提到的，用户编写的 Map 将所有的输入处理成中间状态的键值对，MapReduce 根据中间状态的 Key 将其整理到一起（因为数据在不同的机器上），并将其交给 Reduce。
之后，同样是用户编写的 Reduce 将 Key 相同的中间键值对合并到一起。合并的数据集可能只是一小部分。
下面是一个单词计数的例子：
map (String key, String value) // key document name // value document content for each word w int value: EmitIntermediate (w, &amp;quot;1&amp;quot;); reduce (String key, Iterator value) // key a word // values a list of counts int result = 0; for each v in values: result += ParseInt (v); Emit(AsString (result)); map 函数将出现过的单词与其出现过的次数相关联，这里是1。 reduce 函数将相同单词出现的次数求和。</description></item><item><title>Solution for switching between lowercase and Chinese pinyin with Caps Lock in Jetbrains IDEs</title><link>/article/2020/02/solution-for-switching-pinyin-ime-state-in-jbs/</link><pubDate>Wed, 12 Feb 2020 00:00:00 +0000</pubDate><guid>/article/2020/02/solution-for-switching-pinyin-ime-state-in-jbs/</guid><description>TL;DR:
Add TICapsLockLanguageSwitchCapable - true to your input method&amp;rsquo;s Info.plist[1]
Background Last month I encountered a problem with Chinese input method (Rime, Baidu, Sogou, etc), the symptoms is that I couldn&amp;rsquo;t switch between pinyin and lowercase letters with the Caps Lock which can pressed by my little finger in Jetbrains IDEs, which has been my habit since I used macOS.
Before using third-party input methods, it works well with apple pinyin method.</description></item><item><title>A note of android reverse engineering</title><link>/article/2020/02/reverse-engineering/</link><pubDate>Sat, 01 Feb 2020 00:00:00 +0000</pubDate><guid>/article/2020/02/reverse-engineering/</guid><description>起因 凌晨在 QQ 空间看到一个同校同学发布了一款 App，正在邀请别人参加内测。正巧最近我也在帮朋友写一个小应用，便下载来研究一下。应用的主题很常见，主打校内论坛、交友功能，大概猜到是怎么回事，还是先抓包看看吧。
抓包 Charles 这个工具就不用说了，基本抓过包的朋友都用过。不过想要抓手机应用，前提要求手机和电脑在一个局域网络中。设置代理和安装证书这两个步骤很容易找到教程，这里不再赘述。需要注意的是 Android 7 以后按谷歌要求需要额外修改 APP 的网络安全性配置，我这里参考这篇文章 [1] 得以解决。
抓到包之后看了一眼 Request 和 Response 格式，看上去不太规范。而且虽然加入了 token，但是很多接口没有鉴权，拿到接口直接请求就能修改所有用户的资料。由于是内测，我将开发者的昵称修改以提示其漏洞，同时也在内测群里反馈了，截止目前接口还没有修改。除此之外，修改密码等接口中的密码竟然是明文传输的，这让我不能不担心是否在数据库中也是明文存储密码？于是诞生了 hack 进数据库的想法。
调研 在处理数据库相关问题之前，先判断出其应用的技术栈。后端是拿 php 写的，而据我所知 php 框架经常爆出漏洞，在此基础之上发现是 thinkphp v5.0.24，而此版本已将漏洞修复了。此外又发现服务器上安装了宝塔面板，开发者开启了安全登录入口，默认的后台地址被修改了，这条路径也只能放弃了。
撞库 我之前没有接触过安全方面的技术，但是最简单的撞库的思想还是有的。在网上找了一些密码字典，一共包括5000多个常用的密码，用 hydra[2] 暴力撞库，但是失败了。
SQL 注入 撞库失败后联想到 SQL 注入的方式，找到了 sqlmap[3] 这个工具。拿几个接口都测了一下，没有发现注入点这条路也只能放弃。
逆向工程 既然服务端没有收获，那么就尝试从客户端入手。拿来 apk 解压得到 dex 文件，果然没有加壳。用 dex2jar[4]将其转成 jar。这里遇到一个问题[5]，在 GitHub 上最新的 release(2.1 or later) 已经解决。之后用 Java Decompiler[6] 打开 jar 查看源码。仔细查找后，奇怪地发现所有包都是导入的依赖，没有域名对应的包，也没有开发者编写的代码。这明显不合理。后来想到用 adb 来找当前栈顶 Activity 的方法。
adb shell dumpsys activity activities | sed -En -e &amp;#39;/Running activities/,/Run #0/p&amp;#39; 结果竟然是 uni.</description></item><item><title>Open Source and I - After Alibaba Summer of Code</title><link>/article/2019/08/29/summer-of-code/</link><pubDate>Thu, 29 Aug 2019 00:00:00 +0000</pubDate><guid>/article/2019/08/29/summer-of-code/</guid><description>关于阿里巴巴编程之夏的介绍可以参考 AliOS-things 同学的文章 https://zhuanlan.zhihu.com/p/79863308
借秋招的一个间歇期，记录一下我的开源历程。算是对自己的人生阶段的一个记录。
从小学时使用开源软件成为受益者，到第一次到开源社区中成为贡献者，我用了十年。不求回报地默默贡献，得到他人的肯定便觉得欢欣雀跃，也许这就是开源的魅力所在。
图1，赵老师在 Jenkins 中文社区的发言
我第一次正式参与到开源项目中，是在去年的九月。
去年四月的时候，在上海有幸认识了家辉，我们当时便成为了朋友。也是通过他，我了解到了 GSoC。半年之后，觉得是开始套瓷的时间了，便想挑选几个社区来有针对性的交流。第一个关注的是 Apache 的 Kylin 社区，虽然主要开发者是中国人，但是方向和我期望的不太一样，所以后来没有选择它。后来在 GSoC-CN 中根据往年的申请情况，选择了 Jenkins 社区，巧合的是 Jenkins 中文社区刚刚成立，而 Jenkins 社区中活跃的参与者赵老师 @Rick 又是中国人，所以从九月到第二年的三月我便一直在 Jenkins 社区中做贡献，期间成为了 Jenkins-infra member。
图2，赵老师由 KK 宣布为最有价值参与者
转折发生在二月和三月。在年前我和赵老师提到过想申请他的 multibranch plugin，他也提醒过我多次要提早准备。但是我期间一直没有在其 gitter channel 中发言，二月的时候有一个印度的同学也参与到其中。同时在三月时春招受挫，和在蚂蚁的家纯学长聊了聊，决定放弃 GSoC，参与到 Kafka 中去。
图3，和学长的交流
四月的一个偶然机会，了解到 ASoC 的举办，而其中恰好有我想要深入学习的 Dubbo 社区，于是便在 issue 中留言。我没有马上得到回复，而我又不想错过这次机会，于是在 Jira 中留言、给社区发邮件、给导师发邮件、给 aliopensource 发邮件。久久没有得到回复的我有点绝望，当时又去接触了 Spring Cloud Alibaba 社区。后来乎兴老师在 Jira 中回复了我，@cvictory 也在 issue 中回复了我，aliopensource 和社区也都回复了我邮件，让我先写 proposal。有 GSoC 的经历，其实我的提案早就写完了，但是 ASoC 的提案描述相对来说不够具体，很难有针对性的给出解决方案，就这样踏上了漫长的交流之路&amp;hellip;</description></item><item><title>The analysis and modification of rules of ESLint</title><link>/article/2019/07/the-analysis-and-modification-of-eslint-rules/</link><pubDate>Wed, 03 Jul 2019 00:00:00 +0000</pubDate><guid>/article/2019/07/the-analysis-and-modification-of-eslint-rules/</guid><description>每个互联网大厂都有自己的编码规范，而对规范审查需要有代码扫描平台来对工程师的能力进行评估。在实习的两个月中，我负责的工作的一部分包括代码规范扫描方向，其中对 ESLint 以及 fecs 规则的修改及调整也包括在内。ESLint 在内部保留了一个仓库用于 JS 的规范检查，由于内部代码规范的问题，不可能直接将外部的拿来直接使用。对很少接触 JS 的我来说，npm 的包管理方式冗杂而烦乱，同时该模块是被集成在整个扫描平台中的，所以很少有有效的文档用来参考，通过不断地测试最后终于解决了该部分问题。
规则 no-new 要求 使用 new 关键字必须将其赋值给一个变量，如:
var Vue = new Vue({}) 而内部规范在 Vue 中可以不赋值
new Vue({}) 所以考虑对 ESLint 进行一些定制化配置。
查看官方文档无果之后，考虑找到开发人员，以下为交流过程：
arjenzhou: Hi, because I customized the rules, so I want to build and run eslint locally, what should I do?
platinumazure: @arjenzhou You should be able to install ESLint locally with npm install &amp;ndash;save-dev eslint, and then run with .</description></item></channel></rss>