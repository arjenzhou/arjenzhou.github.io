<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Big Data on 0xab.de</title><link>/categories/big-data/</link><description>Recent content in Big Data on 0xab.de</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Fri, 13 Nov 2020 00:00:00 +0000</lastBuildDate><atom:link href="/categories/big-data/feed.xml" rel="self" type="application/rss+xml"/><item><title>Spark Papers</title><link>/article/2020/11/spark-papers/</link><pubDate>Fri, 13 Nov 2020 00:00:00 +0000</pubDate><guid>/article/2020/11/spark-papers/</guid><description>Spark: Cluster Computing with Working Sets MapReduce （下称 MR）任务包含主要五两个步骤：Map、Sort、Combine、Shuffle、 Reduce，每个 MR 任务在 Map 将数据阶段将数据转换成 K-V 的形式；Reduce 在不同的机器上作聚合运算。Shuffle 更是涉及到巨大的 I/O 操作（主要是网络 I/O）。每个 MR 任务最终会将计算结果写回存储系统。
由于 MR 任务的最终结果会写回存储，那么有两种经典场景对于它来说是低效的：
迭代任务（迭代机器学习算法） 交互式数据分析工具 Spark 提出了 RDD (Resilient Distributed Dataset) 模型来处理此类问题。RDD 是一个被分布在一组机器上的只读的对象集，当一个分区丢失时 RDD 能够很快通过重新计算的方式来重建。RDD 能够被保存在内存中，并以类似 MR 的 并行操作方式 得到重用。RDD 通过一种叫做 血统（lineage） 的概念实现容错：如果 RDD 的一部分丢失了，那么 RDD 有足够的信息（该 RDD 是怎么从其他 RDD 计算出来的）来重建该部分。
在 Spark 中，RDD 以 Scala 对象的形式存在。并且 RDD 能够通过以下几种形式构造出来：
来自共享文件系统（如 HDFS）中的一个文件 并行化（parallelizing） 一个 Scala 集合 转化（transforming）于一个已经存在的 RDD 改变一个已存在 RDD 的持久性（persistence） cache：将 RDD 暂存于内存以便稍后重用 save：将 RDD 存于类似 HDFS 的分布式文件系统 对于 cache 这种情况来说，如果集群中没有足够的内存来缓存一个数据集（dataset）的所有部分，那么 Spark 会在使用它们时重新计算。</description></item></channel></rss>